---
layout: post
tag : complexity, cost
category: education
title: "O"
description: big O, time complexity, space complexity, math
author: Sarah Chen
image: images/posts/photos/IMG_0875.JPG

---
In working in financial services, the goal was to get insight, build models, and predict/forecast.

However, in the machine learning era, the goals and capacities of analytics have far expanded beyond statistics and modeling. Modelers may need to implement the models themselves.  In order to implement efficient models, it is necessary to understand computer science fundamentals.  This post is about how we measure efficiency.  
  
- [The Big O metric](#the-big-o-metric)
- [Time complexity](#time-complexity)
- [Space complexity](#space-complexity)
- [Example: in-place sort integer list](#example-in-place-sort-integer-list)
  
# The Big O metric
In order to measure run time efficiency, the big $$O$$ metric is used. 

In analytic number theory class by my late professor Patrick Gallagher,the big O metric was associated with whether two different representations are *aymptotically* close. 
![Professor Patrick Gallagher](../images/posts/gallagher.PNG)

If $$S$$ is a set and $$f$$ and $$g$$ are functions $$S$$ →$$R$$, we say that$$f = O(g)$$ if there exists an $$k > 0$$ such that $$\|f(s)\| ≤ kg(s)$$ for all $$s∈S$$.  

# Time complexity
Therefore,$$O(1)$$ means some constant (time). Similarly,$$O(2)$$ or $$O(100)$$ also mean constant, as long as the number is fixed. 

$$O(n)$$ means linear as in $$k*n$$ for some $$k>0$$.

In computer science, the big $$O$$ is used as a time efficiency metric for data structure: how much time it takes to do each of the following essential functions:
1. Access (to get)
2. Search (to find)
3. Insert (to add)
4. Delete (to remove)

In computer science context, constant time (e.g. $$O(1)$$) means that the amound of time it takes to do something (something could be one of the 4 tasks above) is independent of the size of the data.  The size of data $$n$$ is absent from the $$O$$. Constant time is the most efficient but also difficult to achieve. 

Time complexity or run time | $$O$$ as a function of data size$$n$$ |Example | Explain
---------|----------|---------|---------
constant |$$O(1)$$ |indexed data |data size is irrelevant
log n |$$O(log(n))$$ | binary search |data size is relevant, but unit "cost" decreases as data size increases
linear |$$O(n)$$ | accessing |time is a linear function of data size
linear*log |$$O(nlog(n))$$ | | As we can see, its slope $$log(n)+1$$ is a positive function of $$n$$
power |$$O(n^2)$$ | inserting/deleting| slope $$2n$$ is a positive function of $$n$$
exponential |$$O(2^n)$$ | | the worst in efficiency

In the following code, 
1. <span class="coding">print_1st_one</span> prints the first item regardless how big the input is.  The run time is a constant.
2. <span class="coding">print_all</span> prints all input. So it is a linear function of the input length.  The run time is $2*n$, which is $O(n)$. 
2. <span class="coding">print_all_ordered_pairs</span> prints all ordered pairs (like a multiplication table) in a double loop. The run time is $O(n^2)$. 

<div class="code-head"><span>code</span>O_time.py</div>

```py
# O(1)
def print_1st_one(s):
    print(s[0])

# O(n)
def print_all(s):
    for i in s:
        print(i)
    for j in s:
        print(j)

# O(n^2)
def print_all_ordered_pairs(s):
    for i in s:
        for j in s:
            print(i,j)
```

In general, those with less flexibility are faster for certain basic tasks. For example, in Python tuple are immutable (cannot add or change) is faster than list (Note that although tuple elements cannot be changed, but a list within a tuple can be changed, for example ([1,2,3],)). 

Some data structures are very inefficient in terms of time, but they are very useful for what they are made to do. 

![time complexity](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Comparison_computational_complexity.svg/330px-Comparison_computational_complexity.svg.png)

# Space complexity
Space complexity is about **how much memory running the code will take as a function of the input size**.  Space complexity is similar to time complexity.  **In place** operations are the least costly in memory space. 

In the following code, 
1. <span class="coding">say_n_time</span> although it says n times, it says the same thing, which takes constant space $O(1)$. 
2. <span class="coding">get_largest</span>, like <span class="coding">say_n_time</span>, even though the input has length $n$, the memory required is constant $O(1)$. 
2. <span class="coding">say_n_times_and_remember_all</span> requires memory space is $O(n)$ as the computer has to remember all the words printed in the past. 
<div class="code-head"><span>code</span>O_space.py</div>

```py
# O(1)
def say_n_times(n):
    for i in range(n):
        print("I love you")

# O(1)
def get_largest(nums):
    largest = float('-inf')
    for i in nums:
        if i > largest:
            largest = i
    return largest

# O(n)
def say_n_times_and_remember_all(n):
    remembered = []
    for i in range(n):
        print("I love you ")
        remembered.append(i)
```

# Example: in-place sort integer list 

* **Problem**:
We want to sort in place a list of integers such that all even numbers are before all odd numbers. 

The way to do it, as other space $$O(1)$$ problems, is to use partition into 3 parts: left is even, middle is unsorted, and the right side is odd.  

Two index pointers are needed to partition a list in 3.  

We start checking from the left side. 

1. Whenever an even number is encountered, left index moves forward by 1
2. If the number is odd, we swap the number where the left index is with the number where the right index is.  Since we are sure that the number moving to the right is odd, we can decrement the right index by 1
> Note that the number where the right index was at can be even or odd, the number that is coming to the left side can be even or odd. Hence we cannot increment the left index. 
3. Continue until even_idx and odd_idx cross

<div class="code-head"><span>code</span>even_odd_O_1.py</div>

```py

def sort_integers(lt):
    # even_idx and odd_idx are indices of left and right pointer
    even_idx, odd_idx = 0, len(lt) - 1 # length - 1 because of Python index starts from 0 and ends at length -1
    while even_idx < odd_idx:
        # check even 
        if lt[even_idx] % 2 == 0:
            even_idx += 1 # left index move forward by 1
        else:
            lt[even_idx], lt[odd_idx] = lt[odd_idx], lt[even_idx] # swap so that these two numbers become sorted
            odd_idx -= 1 # right index move forward by 1
            # the reason why we are not incrementing even_idx by 1 is that lt[odd_idx] can be odd
    return lt
myList = [2, 3, 5, 6, 1, 2]
print(sort_integers(myList))
# [2, 6, 5, 3]

```